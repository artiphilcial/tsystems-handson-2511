{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sales Assistant Prompt Template Deployment\n",
    "\n",
    "This notebook shows how to create and deploy a Prompt Template for the Sales Assistant that can be used with the chat application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ibm-watsonx-ai | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models.prompts import PromptTemplateManager, PromptTemplate\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai import APIClient\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=getpass.getpass(\"Please enter your watsonx.ai API key: \"),\n",
    ")\n",
    "\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Sales Assistant Prompt Template\n",
    "\n",
    "This template includes:\n",
    "- System instruction for the Sales Assistant role\n",
    "- Conversation history variable\n",
    "- User question variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Prompt Template Manager\n",
    "prompt_mgr = PromptTemplateManager(\n",
    "    credentials=credentials,\n",
    "    project_id=project_id\n",
    ")\n",
    "\n",
    "# Define the Sales Assistant prompt template\n",
    "sales_assistant_template = PromptTemplate(\n",
    "    name=\"Sales Assistant - Deutsche Telekom\",\n",
    "    model_id=\"mistralai/mistral-small-3-1-24b-instruct-2503\",  # You can change this\n",
    "    model_params={\n",
    "        GenParams.DECODING_METHOD: \"greedy\",\n",
    "        GenParams.MAX_NEW_TOKENS: 1000,\n",
    "        GenParams.TEMPERATURE: 0.7,\n",
    "        GenParams.STOP_SEQUENCES: [\"<|user|>\", \"\\n\\nUser:\", \"\\nUser:\"]\n",
    "    },\n",
    "    description=\"Sales assistant for Deutsche Telekom products and services\",\n",
    "    task_ids=[\"generation\"],\n",
    "    input_variables=[\"conversation_history\", \"user_question\"],\n",
    "    instruction=\"\"\"You are a sales assistant for Deutsche Telekom. Help the customer by answering their specific question about products and services. Only respond as the sales assistant - do not continue the conversation on behalf of the customer.\n",
    "\n",
    "Previous conversation:\n",
    "{conversation_history}\n",
    "\"\"\",\n",
    "    input_prefix=\"Customer\",\n",
    "    output_prefix=\"Sales Assistant\",\n",
    "    input_text=\"{user_question}\",\n",
    "    examples=[\n",
    "        [\n",
    "            \"What mobile plans do you offer?\",\n",
    "            \"We offer a variety of mobile plans to suit different needs! Our plans include unlimited data options, family plans with shared data, and flexible prepaid options. Would you like me to provide more details about a specific type of plan?\"\n",
    "        ],\n",
    "        [\n",
    "            \"Do you have internet packages for home?\",\n",
    "            \"Yes, we have several home internet packages! We offer fiber optic connections with speeds up to 1 Gbps, as well as DSL options. Our packages often include TV and phone services as well. What speed range are you interested in?\"\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Store the prompt template\n",
    "stored_template = prompt_mgr.store_prompt(prompt_template=sales_assistant_template)\n",
    "print(f\"‚úÖ Prompt Template created with ID: {stored_template.prompt_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API Client\n",
    "client = APIClient(wml_credentials=credentials)\n",
    "client.set.default_project(project_id)\n",
    "\n",
    "# Create deployment\n",
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"Sales Assistant Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
    "    client.deployments.ConfigurationMetaNames.BASE_MODEL_ID: \"mistralai/mistral-small-3-1-24b-instruct-2503\"\n",
    "}\n",
    "\n",
    "deployment_details = client.deployments.create(\n",
    "    artifact_id=stored_template.prompt_id,\n",
    "    meta_props=meta_props\n",
    ")\n",
    "\n",
    "deployment_id = deployment_details.get(\"metadata\", {}).get(\"id\")\n",
    "print(f\"\\n‚úÖ Deployment created successfully!\")\n",
    "print(f\"\\nüìã Deployment ID: {deployment_id}\")\n",
    "print(f\"\\n‚öôÔ∏è  Add this to your .env file:\")\n",
    "print(f\"PROMPT_TEMPLATE_DEPLOYMENT_ID={deployment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "\n",
    "# Initialize model with deployment\n",
    "model = ModelInference(\n",
    "    deployment_id=deployment_id,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id\n",
    ")\n",
    "\n",
    "# Test with a sample question\n",
    "test_question = \"What are your best mobile plans for families?\"\n",
    "\n",
    "response = model.generate_text(\n",
    "    params={\n",
    "        \"prompt_variables\": {\n",
    "            \"conversation_history\": \"No previous conversation\",\n",
    "            \"user_question\": test_question\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\nüß™ Test Question: {test_question}\")\n",
    "print(f\"\\nüí¨ Response:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View All Deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Copy the `PROMPT_TEMPLATE_DEPLOYMENT_ID` from above\n",
    "2. Add it to your `.env` file in the chat application\n",
    "3. Restart the Streamlit app\n",
    "4. The app will automatically use the deployed prompt template!\n",
    "\n",
    "### Benefits of Using Deployed Templates:\n",
    "- ‚úÖ Centralized prompt management\n",
    "- ‚úÖ Version control for prompts\n",
    "- ‚úÖ Update prompts without changing code\n",
    "- ‚úÖ Consistent behavior across applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}